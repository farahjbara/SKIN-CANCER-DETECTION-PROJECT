{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farahjbara/SKIN-CANCER-DETECTION-PROJECT/blob/main/Training_CNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfURusoXDTfr"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "rOHWFS-WPcNt",
        "outputId": "27f848ba-ebc8-4ed4-f483-0daf40bf75fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMcYyxx0DVSo"
      },
      "source": [
        "train_dir='/content/drive/MyDrive/Android-App-Skin-Cancer-Detector/Android-App-Skin-Cancer-Detector/Training/Dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktn0SkgXDXP8"
      },
      "source": [
        "Labels = ['Benign', 'Malignant']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubSv3rnyDZBE"
      },
      "source": [
        "print (\"class : \") \n",
        "for i in range(len(Labels)): \n",
        "    print (i, end = \" \") \n",
        "    print (Labels[i]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkVtS4TkDarf"
      },
      "source": [
        "print('Number of classes:',len(Labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXdEgAj5DcBL"
      },
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) \n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/2\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "BATCH_SIZE = 16 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYNXTeVj-K_w"
      },
      "source": [
        "IMAGE_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAGIZTBfDdcJ"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, \n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2, \n",
        "      zoom_range=0.2,\n",
        "      fill_mode='nearest',\n",
        "      validation_split=0.4,\n",
        "      brightness_range=[0.4,1.5])\n",
        "  \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    subset=\"training\", \n",
        "    shuffle=True, \n",
        "    seed=42,\n",
        "    color_mode=\"rgb\", \n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    shuffle=False, \n",
        "    seed=42,\n",
        "    color_mode=\"rgb\", \n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\",\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEUMzRB3De5z"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,input_shape=IMAGE_SIZE+(3,), output_shape=[FV_SIZE]  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Sc06P1DgUu"
      },
      "source": [
        "do_fine_tuning = False \n",
        "if do_fine_tuning:\n",
        "  feature_extractor.trainable = True\n",
        "  for layer in base_model.layers[-30:]:\n",
        "    layer.trainable =True\n",
        "  \n",
        "else:\n",
        "  feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHw7IFhLDhzn"
      },
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    feature_extractor,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "#model.build((None,)+IMAGE_SIZE+(3,))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqW5HaZ0DjWK"
      },
      "source": [
        "LEARNING_RATE = 0.001 \n",
        "model.compile(\n",
        "   optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), \n",
        "   loss='categorical_crossentropy',\n",
        "   metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "reduce_learning_rate = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 3, verbose = 1, factor = 0.3, min_lr = 0.00001)\n",
        "checkpoint = ModelCheckpoint('modelb.h5', monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 10, verbose = 1, restore_best_weights = True)\n",
        "\n",
        "callbacks = [reduce_learning_rate, checkpoint, early_stopping]"
      ],
      "metadata": {
        "id": "pLggRCNttqiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "EPOCHS=300\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks = callbacks,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "metadata": {
        "id": "eKS4GWj8kUyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "reduce_learning_rate = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 3, verbose = 1, factor = 0.3, min_lr = 0.00001)\n",
        "checkpoint = ModelCheckpoint('modelb.h5', monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 10, verbose = 1, restore_best_weights = True)\n",
        "\n",
        "callbacks = [reduce_learning_rate, checkpoint, early_stopping]"
      ],
      "metadata": {
        "id": "7MQE6uqd_AH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oWHMV0_Dn4K"
      },
      "source": [
        "                                                                                                                                                                                                                                                                                                                                                                                                     import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xd1vA4qDpj7"
      },
      "source": [
        "import random\n",
        "import cv2\n",
        "def upload(filename):\n",
        "    img = cv2.imread(os.path.join(train_dir, filename))\n",
        "    img = cv2.resize(img, (224, 224) )\n",
        "    img = img /255            \n",
        "                                                        \n",
        "    return img\n",
        "\n",
        "def pre_result(image):\n",
        "    x = model.predict(np.asarray([img]))[0]\n",
        "    classx = np.argmax(x)\n",
        "    \n",
        "    return {Labels[classx]: x[classx]}\n",
        "\n",
        "images = random.sample(validation_generator.filenames, 16)\n",
        "\n",
        "for idx, filename in enumerate(images):\n",
        "    \n",
        "    \n",
        "    img = upload(filename)\n",
        "    prediction = pre_result(img)\n",
        "    print(\"class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n",
        "    plt.imshow(img)\n",
        "    plt.figure(idx)    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqM6Df0cDrE8"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "predictions1 = model.predict(validation_generator, steps=len(validation_generator))\n",
        "y = np.argmax(predictions1, axis=1)\n",
        "\n",
        "print('Classification Report')\n",
        "cr = classification_report(y_true=validation_generator.classes, y_pred=y, target_names=validation_generator.class_indices)\n",
        "print(cr)\n",
        "\n",
        "evaluates = model.evaluate(validation_generator)\n",
        "\n",
        "print(evaluates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq1fUcu1DssZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(validation_generator.classes, y)\n",
        "df = pd.DataFrame(cm, columns=validation_generator.class_indices)\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.heatmap(df, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32,(3,3),strides=(1, 1),activation='relu',padding='same', input_shape=(224, 224, 3)), \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64,(3,3),strides=(1, 1) ,padding='same',activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128,(3,3),strides=(1, 1),padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256,(3,3),strides=(1, 1),padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "UQR17o_LNN0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9no8-aoGQZo"
      },
      "source": [
        "cd /content/drive/MyDrive/Buffml/code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUB9-0jnH9MP"
      },
      "source": [
        "#Export as saved model and convert to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EQmFGdZGX1H"
      },
      "source": [
        "import time\n",
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "tf.keras.models.save_model(model, export_path)\n",
        "\n",
        "export_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOpETStsGr4-"
      },
      "source": [
        "# Now confirm that we can reload it, and it still gives the same results\n",
        "reloaded = tf.keras.models.load_model(export_path, custom_objects={'KerasLayer':hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYBuzvmCH8Ys"
      },
      "source": [
        "def predict_reload(image):\n",
        "    probabilities = reloaded.predict(np.asarray([img]))[0]\n",
        "    class_idx = np.argmax(probabilities)\n",
        "    \n",
        "    return {Labels[class_idx]: probabilities[class_idx]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH730cT7INym"
      },
      "source": [
        "for idx, filename in enumerate(random.sample(validation_generator.filenames, 2)):\n",
        "    print(\"SOURCE: class: %s, file: %s\" % (os.path.split(filename)[0], filename))\n",
        "    \n",
        "    img = upload(filename)\n",
        "    prediction = predict_reload(img)\n",
        "    print(\"PREDICTED: class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n",
        "    plt.imshow(img)\n",
        "    plt.figure(idx)    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp7xvcCsIPlV"
      },
      "source": [
        "# convert the model to TFLite\n",
        "!mkdir \"tflite_models\"\n",
        "TFLITE_MODEL = \"tflite_models/model.tflite\"\n",
        "\n",
        "\n",
        "# Get the concrete function from the Keras model.\n",
        "run_model = tf.function(lambda x : reloaded(x))\n",
        "\n",
        "# Save the concrete function.\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")\n",
        "\n",
        "# Convert the model to standard TensorFlow Lite model\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converted_tflite_model = converter.convert()\n",
        "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTEBp7TpJACU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}